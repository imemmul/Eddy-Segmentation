{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import SegformerFeatureExtractor\n",
    "import sys\n",
    "sys.path.insert(1, '../utils/')\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_dataloaders import EddyDatasetTrain, EddyDatasetValid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emir/anaconda3/envs/emirenv/lib/python3.10/site-packages/transformers/models/segformer/image_processing_segformer.py:102: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "feature_extractor.reduce_labels = False\n",
    "feature_extractor.size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_dir = \"/home/emir/dev/segmentation_eddies/downloads/data4test/aug_data/\"\n",
    "mask_image_dir = \"/home/emir/dev/segmentation_eddies/downloads/data4test/aug_label/\"\n",
    "val_image_dir = \"/home/emir/dev/segmentation_eddies/downloads/data4test/data/\"\n",
    "val_mask_dir = \"/home/emir/dev/segmentation_eddies/downloads/data4test/label/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(os.listdir(input_image_dir))\n",
    "split = int(0.85 * train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = EddyDatasetTrain(feature_extractor=feature_extractor, input_image_dir=input_image_dir, mask_image_dir=mask_image_dir, split=split)\n",
    "valid_data = EddyDatasetValid(feature_extractor=feature_extractor, input_image_dir=val_image_dir, mask_image_dir=val_mask_dir, split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9180, 1620)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_data(data):\n",
    "    rand_ind = np.random.randint(len(train_data))\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    rows = 1\n",
    "    columns = 2\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow((data[rand_ind]['pixel_values']).permute(1,2,0))\n",
    "    plt.axis(False)\n",
    "    plt.title(\"Image\")\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow((data[rand_ind]['labels']))\n",
    "    plt.axis(False)\n",
    "    plt.title(\"Label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_train_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegformerImageProcessor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_reduce_labels\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"SegformerFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"SegformerImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"reduce_labels\": false,\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": 128\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = \"nvidia/segformer-b0-finetuned-ade-512-512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerForSemanticSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emir/anaconda3/envs/emirenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:594: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.3.proj.weight', 'decode_head.batch_norm.running_mean', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.running_var', 'decode_head.classifier.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.batch_norm.bias', 'decode_head.batch_norm.weight', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerForSemanticSegmentation\n",
    "import json\n",
    "from huggingface_hub import cached_download, hf_hub_url\n",
    "\n",
    "# load id2label mapping from a JSON on the hub\n",
    "repo_id = \"huggingface/label-files\"\n",
    "filename = \"ade20k-id2label.json\"\n",
    "id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type='dataset')), \"r\"))\n",
    "id2label = {int(k): v for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# define model\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b0\",\n",
    "                                                         num_labels=150, \n",
    "                                                         id2label=id2label, \n",
    "                                                         label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_segformer(model, train_dataloader, optimizer, device, epochs, metric):\n",
    "  model.to(device)\n",
    "\n",
    "  model.train()\n",
    "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    print(\"Epoch:\", epoch)\n",
    "    for idx, batch in enumerate((train_dataloader)):\n",
    "          # get the inputs;\n",
    "          pixel_values = batch[\"pixel_values\"].to(device)\n",
    "          labels = batch[\"labels\"].to(device)\n",
    "\n",
    "          # zero the parameter gradients\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # forward + backward + optimize\n",
    "          outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "          loss, logits = outputs.loss, outputs.logits # no loss function declared model calculates itself\n",
    "          \n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          # evaluate\n",
    "          with torch.no_grad():\n",
    "            upsampled_logits = nn.functional.interpolate(logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            predicted = upsampled_logits.argmax(dim=1)\n",
    "            \n",
    "            # note that the metric expects predictions + labels as numpy arrays\n",
    "            metric.add_batch(predictions=predicted.detach().cpu().numpy(), references=labels.detach().cpu().numpy())\n",
    "\n",
    "          # let's print loss and metrics every 100 batches\n",
    "          if idx % 100 == 0:\n",
    "            metrics = metric._compute(num_labels=len(id2label), \n",
    "                                    ignore_index=255,\n",
    "                                    reduce_labels=False,\n",
    "                                    references=labels.cpu().numpy(),\n",
    "                                    predictions=predicted.cpu().numpy()\n",
    "                                      # we've already reduced the labels before)\n",
    "            )\n",
    "\n",
    "            print(\"Loss:\", loss.item())\n",
    "            print(\"Mean_iou:\", metrics[\"mean_iou\"])\n",
    "            print(\"Mean accuracy:\", metrics[\"mean_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00006)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emir/.cache/huggingface/modules/datasets_modules/metrics/mean_iou/d4add40cf977cdd73590b5873fa830f3f13adb678f6777a29fb07b7c81d14342/mean_iou.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  iou = total_area_intersect / total_area_union\n",
      "/home/emir/.cache/huggingface/modules/datasets_modules/metrics/mean_iou/d4add40cf977cdd73590b5873fa830f3f13adb678f6777a29fb07b7c81d14342/mean_iou.py:259: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.121739864349365\n",
      "Mean_iou: 0.0\n",
      "Mean accuracy: 0.0\n",
      "Loss: 3.4804975986480713\n",
      "Mean_iou: 0.013174444879763773\n",
      "Mean accuracy: 0.8265348553461647\n",
      "Loss: 2.217844009399414\n",
      "Mean_iou: 0.12366023303325505\n",
      "Mean accuracy: 0.7268699954352695\n",
      "Epoch: 1\n",
      "Loss: 1.3992747068405151\n",
      "Mean_iou: 0.5718218505692287\n",
      "Mean accuracy: 0.6328798929339253\n",
      "Loss: 0.6970198750495911\n",
      "Mean_iou: 0.6539935341590379\n",
      "Mean accuracy: 0.7154603982169522\n",
      "Loss: 0.36103686690330505\n",
      "Mean_iou: 0.5399551555851334\n",
      "Mean accuracy: 0.5479140279732608\n",
      "Epoch: 2\n",
      "Loss: 0.25978508591651917\n",
      "Mean_iou: 0.623791457671568\n",
      "Mean accuracy: 0.6548506226673608\n",
      "Loss: 0.18022280931472778\n",
      "Mean_iou: 0.642451436009035\n",
      "Mean accuracy: 0.6642187406842721\n",
      "Loss: 0.13232490420341492\n",
      "Mean_iou: 0.6150218925372442\n",
      "Mean accuracy: 0.6299415108279228\n",
      "Epoch: 3\n",
      "Loss: 0.09934397786855698\n",
      "Mean_iou: 0.640383764550135\n",
      "Mean accuracy: 0.6604214362052497\n",
      "Loss: 0.09231345355510712\n",
      "Mean_iou: 0.6161383018597628\n",
      "Mean accuracy: 0.6280338939955527\n",
      "Loss: 0.08211514353752136\n",
      "Mean_iou: 0.6054853852699104\n",
      "Mean accuracy: 0.6233470119670226\n",
      "Epoch: 4\n",
      "Loss: 0.09986444562673569\n",
      "Mean_iou: 0.6101806145763816\n",
      "Mean accuracy: 0.6335607495859791\n",
      "Loss: 0.062149446457624435\n",
      "Mean_iou: 0.5410905934938353\n",
      "Mean accuracy: 0.550436337924048\n",
      "Loss: 0.06126488000154495\n",
      "Mean_iou: 0.5849952557525098\n",
      "Mean accuracy: 0.60331898940569\n",
      "Epoch: 5\n",
      "Loss: 0.05778351053595543\n",
      "Mean_iou: 0.5747580848142442\n",
      "Mean accuracy: 0.58296043406239\n",
      "Loss: 0.05612706393003464\n",
      "Mean_iou: 0.6309521013161916\n",
      "Mean accuracy: 0.652768461898967\n",
      "Loss: 0.048943087458610535\n",
      "Mean_iou: 0.6586105059221034\n",
      "Mean accuracy: 0.6787034634916449\n",
      "Epoch: 6\n",
      "Loss: 0.05237008258700371\n",
      "Mean_iou: 0.6406986079635977\n",
      "Mean accuracy: 0.6610826332736238\n",
      "Loss: 0.05467282608151436\n",
      "Mean_iou: 0.6316156896791891\n",
      "Mean accuracy: 0.6531696593706534\n",
      "Loss: 0.04541712626814842\n",
      "Mean_iou: 0.6267146998670761\n",
      "Mean accuracy: 0.6504955389679195\n",
      "Epoch: 7\n",
      "Loss: 0.04379875957965851\n",
      "Mean_iou: 0.659947830944861\n",
      "Mean accuracy: 0.6840304312385419\n",
      "Loss: 0.043973829597234726\n",
      "Mean_iou: 0.6277662646412884\n",
      "Mean accuracy: 0.6423261934668281\n",
      "Loss: 0.042959410697221756\n",
      "Mean_iou: 0.6522720617812962\n",
      "Mean accuracy: 0.6683040371926461\n",
      "Epoch: 8\n",
      "Loss: 0.043649617582559586\n",
      "Mean_iou: 0.6279880698537944\n",
      "Mean accuracy: 0.6433535619403374\n",
      "Loss: 0.032859254628419876\n",
      "Mean_iou: 0.6759262605877343\n",
      "Mean accuracy: 0.705616102125191\n",
      "Loss: 0.03436547890305519\n",
      "Mean_iou: 0.6431985559688521\n",
      "Mean accuracy: 0.6543358357508222\n",
      "Epoch: 9\n",
      "Loss: 0.04208604246377945\n",
      "Mean_iou: 0.6609733671345853\n",
      "Mean accuracy: 0.6943129335958058\n",
      "Loss: 0.03501596301794052\n",
      "Mean_iou: 0.6791437908878295\n",
      "Mean accuracy: 0.7017830754849452\n",
      "Loss: 0.04390697926282883\n",
      "Mean_iou: 0.6870932852254965\n",
      "Mean accuracy: 0.7597582205088184\n",
      "Epoch: 10\n",
      "Loss: 0.03676559776067734\n",
      "Mean_iou: 0.7128527660121642\n",
      "Mean accuracy: 0.743138220445079\n",
      "Loss: 0.03571503609418869\n",
      "Mean_iou: 0.6835096171025362\n",
      "Mean accuracy: 0.7131036825611765\n",
      "Loss: 0.034085504710674286\n",
      "Mean_iou: 0.6444380176681472\n",
      "Mean accuracy: 0.663567688055741\n",
      "Epoch: 11\n",
      "Loss: 0.034901753067970276\n",
      "Mean_iou: 0.7395279058108898\n",
      "Mean accuracy: 0.7744909448193318\n",
      "Loss: 0.03702042996883392\n",
      "Mean_iou: 0.6289201636140861\n",
      "Mean accuracy: 0.6375817770365406\n",
      "Loss: 0.03575465828180313\n",
      "Mean_iou: 0.6681666889534548\n",
      "Mean accuracy: 0.693849026878419\n",
      "Epoch: 12\n",
      "Loss: 0.03565841168165207\n",
      "Mean_iou: 0.6374249731597562\n",
      "Mean accuracy: 0.6578023551123678\n",
      "Loss: 0.029097700491547585\n",
      "Mean_iou: 0.6912374428620465\n",
      "Mean accuracy: 0.7488885140980182\n",
      "Loss: 0.035292405635118484\n",
      "Mean_iou: 0.6884013804972391\n",
      "Mean accuracy: 0.7166696345531203\n",
      "Epoch: 13\n",
      "Loss: 0.04129845276474953\n",
      "Mean_iou: 0.6448137140356801\n",
      "Mean accuracy: 0.6669667964460193\n",
      "Loss: 0.03503415361046791\n",
      "Mean_iou: 0.661190169808785\n",
      "Mean accuracy: 0.6869056372703372\n",
      "Loss: 0.030992917716503143\n",
      "Mean_iou: 0.6817916020052914\n",
      "Mean accuracy: 0.716785707512693\n",
      "Epoch: 14\n",
      "Loss: 0.0319887176156044\n",
      "Mean_iou: 0.692515868352929\n",
      "Mean accuracy: 0.7305681355999538\n",
      "Loss: 0.03659059479832649\n",
      "Mean_iou: 0.7024882900980168\n",
      "Mean accuracy: 0.730853716738021\n",
      "Loss: 0.029489096254110336\n",
      "Mean_iou: 0.666330257450034\n",
      "Mean accuracy: 0.6986927901594455\n",
      "Epoch: 15\n",
      "Loss: 0.03259800374507904\n",
      "Mean_iou: 0.7439672401516682\n",
      "Mean accuracy: 0.7892844277882796\n",
      "Loss: 0.02542824111878872\n",
      "Mean_iou: 0.7150236681771746\n",
      "Mean accuracy: 0.7474965402551457\n",
      "Loss: 0.02972821705043316\n",
      "Mean_iou: 0.7030548874645298\n",
      "Mean accuracy: 0.7459323577502012\n",
      "Epoch: 16\n",
      "Loss: 0.03537106513977051\n",
      "Mean_iou: 0.6449666774661839\n",
      "Mean accuracy: 0.6643222927208909\n",
      "Loss: 0.024075472727417946\n",
      "Mean_iou: 0.6845886976869517\n",
      "Mean accuracy: 0.7425414147018393\n",
      "Loss: 0.020813709124922752\n",
      "Mean_iou: 0.7138763941884656\n",
      "Mean accuracy: 0.7516598153225644\n",
      "Epoch: 17\n",
      "Loss: 0.03039940819144249\n",
      "Mean_iou: 0.7240375685728525\n",
      "Mean accuracy: 0.756027778062733\n",
      "Loss: 0.02644582837820053\n",
      "Mean_iou: 0.7166436959422173\n",
      "Mean accuracy: 0.7522909785968492\n",
      "Loss: 0.02759515307843685\n",
      "Mean_iou: 0.7332861082178073\n",
      "Mean accuracy: 0.7724708063774169\n",
      "Epoch: 18\n",
      "Loss: 0.030404938384890556\n",
      "Mean_iou: 0.6779295624339107\n",
      "Mean accuracy: 0.6952863902248206\n",
      "Loss: 0.022392841055989265\n",
      "Mean_iou: 0.7212479003607266\n",
      "Mean accuracy: 0.7499028294550786\n",
      "Loss: 0.02956365793943405\n",
      "Mean_iou: 0.6754349727009199\n",
      "Mean accuracy: 0.6958432569575209\n",
      "Epoch: 19\n",
      "Loss: 0.03197765722870827\n",
      "Mean_iou: 0.6737566517893416\n",
      "Mean accuracy: 0.6987489245321346\n",
      "Loss: 0.0342479944229126\n",
      "Mean_iou: 0.721013326246614\n",
      "Mean accuracy: 0.7598820562853822\n",
      "Loss: 0.032433297485113144\n",
      "Mean_iou: 0.6527686287306563\n",
      "Mean accuracy: 0.668252810350727\n",
      "Epoch: 20\n",
      "Loss: 0.02026926353573799\n",
      "Mean_iou: 0.6679950199046624\n",
      "Mean accuracy: 0.6983060671324854\n",
      "Loss: 0.02623649872839451\n",
      "Mean_iou: 0.6787348355637536\n",
      "Mean accuracy: 0.7035303380697062\n",
      "Loss: 0.02440997026860714\n",
      "Mean_iou: 0.7171207023703958\n",
      "Mean accuracy: 0.7463023034606051\n",
      "Epoch: 21\n",
      "Loss: 0.028859905898571014\n",
      "Mean_iou: 0.7216806789806396\n",
      "Mean accuracy: 0.7390430017774745\n",
      "Loss: 0.02831500582396984\n",
      "Mean_iou: 0.6592450297111447\n",
      "Mean accuracy: 0.6945948136841013\n",
      "Loss: 0.02352844923734665\n",
      "Mean_iou: 0.7405828864259105\n",
      "Mean accuracy: 0.7766026914916095\n",
      "Epoch: 22\n",
      "Loss: 0.021281983703374863\n",
      "Mean_iou: 0.6905780218699471\n",
      "Mean accuracy: 0.7072513634691775\n",
      "Loss: 0.025350764393806458\n",
      "Mean_iou: 0.755791088436532\n",
      "Mean accuracy: 0.7813447877450428\n",
      "Loss: 0.021802527830004692\n",
      "Mean_iou: 0.6696109151949108\n",
      "Mean accuracy: 0.7004509880323818\n",
      "Epoch: 23\n",
      "Loss: 0.023273136466741562\n",
      "Mean_iou: 0.7641075195410315\n",
      "Mean accuracy: 0.8311962739154128\n",
      "Loss: 0.027980685234069824\n",
      "Mean_iou: 0.7149636143928346\n",
      "Mean accuracy: 0.7466418705808079\n",
      "Loss: 0.03049352578818798\n",
      "Mean_iou: 0.7184637371198572\n",
      "Mean accuracy: 0.7524002231439327\n",
      "Epoch: 24\n",
      "Loss: 0.02241857349872589\n",
      "Mean_iou: 0.767930718477678\n",
      "Mean accuracy: 0.783602950052919\n",
      "Loss: 0.03179621323943138\n",
      "Mean_iou: 0.7686327928080109\n",
      "Mean accuracy: 0.8310445105960336\n",
      "Loss: 0.030152631923556328\n",
      "Mean_iou: 0.7268256145841405\n",
      "Mean accuracy: 0.7569772395522036\n",
      "Epoch: 25\n",
      "Loss: 0.027289457619190216\n",
      "Mean_iou: 0.6564928150368335\n",
      "Mean accuracy: 0.669206604806913\n",
      "Loss: 0.023611782118678093\n",
      "Mean_iou: 0.6644832247715604\n",
      "Mean accuracy: 0.677849464331699\n",
      "Loss: 0.020804189145565033\n",
      "Mean_iou: 0.7384143421089598\n",
      "Mean accuracy: 0.7635949334904564\n",
      "Epoch: 26\n",
      "Loss: 0.03141859918832779\n",
      "Mean_iou: 0.7267702096812713\n",
      "Mean accuracy: 0.7668135758960667\n",
      "Loss: 0.026539869606494904\n",
      "Mean_iou: 0.7303082062213135\n",
      "Mean accuracy: 0.7595468547689532\n",
      "Loss: 0.029227185994386673\n",
      "Mean_iou: 0.7386808347115119\n",
      "Mean accuracy: 0.7731924878045133\n",
      "Epoch: 27\n",
      "Loss: 0.019263509660959244\n",
      "Mean_iou: 0.7163927734946114\n",
      "Mean accuracy: 0.74513012102207\n",
      "Loss: 0.022960085421800613\n",
      "Mean_iou: 0.7492956208843443\n",
      "Mean accuracy: 0.7962852412115204\n",
      "Loss: 0.021446144208312035\n",
      "Mean_iou: 0.69978021457265\n",
      "Mean accuracy: 0.7444175595292208\n",
      "Epoch: 28\n",
      "Loss: 0.025527644902467728\n",
      "Mean_iou: 0.6679664419001954\n",
      "Mean accuracy: 0.6929323594118023\n",
      "Loss: 0.021111834794282913\n",
      "Mean_iou: 0.7439259714445884\n",
      "Mean accuracy: 0.7734659288108114\n",
      "Loss: 0.020398057997226715\n",
      "Mean_iou: 0.7395784326955462\n",
      "Mean accuracy: 0.7654404697389099\n",
      "Epoch: 29\n",
      "Loss: 0.019666044041514397\n",
      "Mean_iou: 0.7382284949887123\n",
      "Mean accuracy: 0.799276998776024\n",
      "Loss: 0.02292516641318798\n",
      "Mean_iou: 0.7727299055960712\n",
      "Mean accuracy: 0.8040240364723235\n",
      "Loss: 0.023911545053124428\n",
      "Mean_iou: 0.7668067932876879\n",
      "Mean accuracy: 0.7959501632425008\n",
      "Epoch: 30\n",
      "Loss: 0.021170783787965775\n",
      "Mean_iou: 0.7549764796445497\n",
      "Mean accuracy: 0.7893751851902315\n",
      "Loss: 0.020131807774305344\n",
      "Mean_iou: 0.7391805048759832\n",
      "Mean accuracy: 0.7798727563943895\n",
      "Loss: 0.02362198755145073\n",
      "Mean_iou: 0.7048202917028656\n",
      "Mean accuracy: 0.7292547337157824\n",
      "Epoch: 31\n",
      "Loss: 0.026189079508185387\n",
      "Mean_iou: 0.7693590239888356\n",
      "Mean accuracy: 0.7983017203140448\n",
      "Loss: 0.018281614407896996\n",
      "Mean_iou: 0.7666756609115402\n",
      "Mean accuracy: 0.8208222615229921\n",
      "Loss: 0.027261240407824516\n",
      "Mean_iou: 0.744672354555849\n",
      "Mean accuracy: 0.7787860344121935\n",
      "Epoch: 32\n",
      "Loss: 0.017838651314377785\n",
      "Mean_iou: 0.8045534863261858\n",
      "Mean accuracy: 0.8320425875598592\n",
      "Loss: 0.01870836690068245\n",
      "Mean_iou: 0.7918703541511583\n",
      "Mean accuracy: 0.8210520344506543\n",
      "Loss: 0.01634407602250576\n",
      "Mean_iou: 0.7660369599096533\n",
      "Mean accuracy: 0.8056802356283861\n",
      "Epoch: 33\n",
      "Loss: 0.024758700281381607\n",
      "Mean_iou: 0.7200333342451183\n",
      "Mean accuracy: 0.7501628157330072\n",
      "Loss: 0.022658077999949455\n",
      "Mean_iou: 0.7701331327272019\n",
      "Mean accuracy: 0.7933744136887697\n",
      "Loss: 0.021070940420031548\n",
      "Mean_iou: 0.7483307757493451\n",
      "Mean accuracy: 0.7911649421187403\n",
      "Epoch: 34\n",
      "Loss: 0.022891901433467865\n",
      "Mean_iou: 0.7803764887486591\n",
      "Mean accuracy: 0.8206484837102471\n",
      "Loss: 0.02283991500735283\n",
      "Mean_iou: 0.7516706127077742\n",
      "Mean accuracy: 0.7950981400264692\n",
      "Loss: 0.020535094663500786\n",
      "Mean_iou: 0.8093527935275977\n",
      "Mean accuracy: 0.8505145510006582\n",
      "Epoch: 35\n",
      "Loss: 0.025394471362233162\n",
      "Mean_iou: 0.7337562336874583\n",
      "Mean accuracy: 0.7534425471947943\n",
      "Loss: 0.02016451768577099\n",
      "Mean_iou: 0.7723384154725852\n",
      "Mean accuracy: 0.8083057306821131\n",
      "Loss: 0.01808890886604786\n",
      "Mean_iou: 0.794649278031641\n",
      "Mean accuracy: 0.8299960190876314\n",
      "Epoch: 36\n",
      "Loss: 0.021616995334625244\n",
      "Mean_iou: 0.7712381974892918\n",
      "Mean accuracy: 0.8033410931591238\n",
      "Loss: 0.018821386620402336\n",
      "Mean_iou: 0.7726373002896689\n",
      "Mean accuracy: 0.8068583868854764\n",
      "Loss: 0.024842018261551857\n",
      "Mean_iou: 0.7655539514295711\n",
      "Mean accuracy: 0.7877661056268072\n",
      "Epoch: 37\n",
      "Loss: 0.02292204461991787\n",
      "Mean_iou: 0.7423195577489049\n",
      "Mean accuracy: 0.7801156101494465\n",
      "Loss: 0.01670604757964611\n",
      "Mean_iou: 0.7387173130526393\n",
      "Mean accuracy: 0.7706591449200643\n",
      "Loss: 0.017934098839759827\n",
      "Mean_iou: 0.7774099708348858\n",
      "Mean accuracy: 0.8138990826596112\n",
      "Epoch: 38\n",
      "Loss: 0.018273359164595604\n",
      "Mean_iou: 0.7328699711739454\n",
      "Mean accuracy: 0.7550146472704315\n",
      "Loss: 0.0238175168633461\n",
      "Mean_iou: 0.7452796905192066\n",
      "Mean accuracy: 0.7836584956802548\n",
      "Loss: 0.0179152674973011\n",
      "Mean_iou: 0.8018085112677629\n",
      "Mean accuracy: 0.8279993136826335\n",
      "Epoch: 39\n",
      "Loss: 0.018185721710324287\n",
      "Mean_iou: 0.7631755630947614\n",
      "Mean accuracy: 0.7990095727518525\n",
      "Loss: 0.01651306077837944\n",
      "Mean_iou: 0.7916118070375645\n",
      "Mean accuracy: 0.8349681526159154\n",
      "Loss: 0.019231997430324554\n",
      "Mean_iou: 0.775373135746336\n",
      "Mean accuracy: 0.8001231560780485\n",
      "Epoch: 40\n",
      "Loss: 0.01962052285671234\n",
      "Mean_iou: 0.7794603480724205\n",
      "Mean accuracy: 0.8086931607596277\n",
      "Loss: 0.016821492463350296\n",
      "Mean_iou: 0.7701272103430208\n",
      "Mean accuracy: 0.8191191132661049\n",
      "Loss: 0.018982142210006714\n",
      "Mean_iou: 0.7769349506271217\n",
      "Mean accuracy: 0.8250390567845318\n",
      "Epoch: 41\n",
      "Loss: 0.022398177534341812\n",
      "Mean_iou: 0.7663898147882295\n",
      "Mean accuracy: 0.7982180661134534\n",
      "Loss: 0.024184802547097206\n",
      "Mean_iou: 0.7990311604722199\n",
      "Mean accuracy: 0.8272921465250728\n",
      "Loss: 0.02250492200255394\n",
      "Mean_iou: 0.7612601324099836\n",
      "Mean accuracy: 0.7986520896391726\n",
      "Epoch: 42\n",
      "Loss: 0.018443306908011436\n",
      "Mean_iou: 0.7955200853941141\n",
      "Mean accuracy: 0.8308524491627927\n",
      "Loss: 0.018649613484740257\n",
      "Mean_iou: 0.8100656223565189\n",
      "Mean accuracy: 0.8367187253103876\n",
      "Loss: 0.015175563283264637\n",
      "Mean_iou: 0.7671574205198718\n",
      "Mean accuracy: 0.7995695310281501\n",
      "Epoch: 43\n",
      "Loss: 0.020655563101172447\n",
      "Mean_iou: 0.7832144023967904\n",
      "Mean accuracy: 0.8229952760085621\n",
      "Loss: 0.017745930701494217\n",
      "Mean_iou: 0.814904424482195\n",
      "Mean accuracy: 0.8452704267266551\n",
      "Loss: 0.022553997114300728\n",
      "Mean_iou: 0.7663963157845816\n",
      "Mean accuracy: 0.7995309357797888\n",
      "Epoch: 44\n",
      "Loss: 0.01904079131782055\n",
      "Mean_iou: 0.7767797123286742\n",
      "Mean accuracy: 0.8060948978776862\n",
      "Loss: 0.022401422262191772\n",
      "Mean_iou: 0.7981263866663784\n",
      "Mean accuracy: 0.8327095851438773\n",
      "Loss: 0.014985108748078346\n",
      "Mean_iou: 0.7879602816451342\n",
      "Mean accuracy: 0.8246618787583659\n",
      "Epoch: 45\n",
      "Loss: 0.014311576262116432\n",
      "Mean_iou: 0.7451412512877955\n",
      "Mean accuracy: 0.7879290799997399\n",
      "Loss: 0.02008388191461563\n",
      "Mean_iou: 0.7543563951118097\n",
      "Mean accuracy: 0.7897263265902834\n",
      "Loss: 0.022693660110235214\n",
      "Mean_iou: 0.7727043844484586\n",
      "Mean accuracy: 0.8136815234049762\n",
      "Epoch: 46\n",
      "Loss: 0.01629195548593998\n",
      "Mean_iou: 0.7787570256051765\n",
      "Mean accuracy: 0.8236294059221079\n",
      "Loss: 0.015665631741285324\n",
      "Mean_iou: 0.813096669594599\n",
      "Mean accuracy: 0.8545384748056659\n",
      "Loss: 0.01739109680056572\n",
      "Mean_iou: 0.8181343383697295\n",
      "Mean accuracy: 0.8589869951127448\n",
      "Epoch: 47\n",
      "Loss: 0.01252647303044796\n",
      "Mean_iou: 0.8310881149661355\n",
      "Mean accuracy: 0.8533618252032099\n",
      "Loss: 0.019834615290164948\n",
      "Mean_iou: 0.8150705710962355\n",
      "Mean accuracy: 0.8420595218403573\n",
      "Loss: 0.013392395339906216\n",
      "Mean_iou: 0.777955141562021\n",
      "Mean accuracy: 0.8195053521588805\n",
      "Epoch: 48\n",
      "Loss: 0.018456630408763885\n",
      "Mean_iou: 0.7847393584765834\n",
      "Mean accuracy: 0.8244371287760157\n",
      "Loss: 0.02076585404574871\n",
      "Mean_iou: 0.7999539044316213\n",
      "Mean accuracy: 0.8306732830549655\n",
      "Loss: 0.018410053104162216\n",
      "Mean_iou: 0.7886598160275513\n",
      "Mean accuracy: 0.8190844868435334\n",
      "Epoch: 49\n",
      "Loss: 0.015953175723552704\n",
      "Mean_iou: 0.7557929417236668\n",
      "Mean accuracy: 0.7883699953833143\n",
      "Loss: 0.018344147130846977\n",
      "Mean_iou: 0.7858992893083017\n",
      "Mean accuracy: 0.814735724457613\n",
      "Loss: 0.015599415637552738\n",
      "Mean_iou: 0.7799049030863755\n",
      "Mean accuracy: 0.8107494873301879\n",
      "Epoch: 50\n",
      "Loss: 0.01769235171377659\n",
      "Mean_iou: 0.7811708078609135\n",
      "Mean accuracy: 0.8165765189802612\n",
      "Loss: 0.017974479123950005\n",
      "Mean_iou: 0.7824366182724773\n",
      "Mean accuracy: 0.8037637845060139\n",
      "Loss: 0.014095218852162361\n",
      "Mean_iou: 0.8111352653085967\n",
      "Mean accuracy: 0.836949367356468\n",
      "Epoch: 51\n",
      "Loss: 0.019512202590703964\n",
      "Mean_iou: 0.7879195039127556\n",
      "Mean accuracy: 0.8274455323384695\n",
      "Loss: 0.017634065821766853\n",
      "Mean_iou: 0.8260404735571328\n",
      "Mean accuracy: 0.8603286676887757\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_segformer(model\u001b[39m=\u001b[39;49mmodel, train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader, metric\u001b[39m=\u001b[39;49mmetric, optimizer\u001b[39m=\u001b[39;49moptimizer, device\u001b[39m=\u001b[39;49mdevice, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m save_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./output/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), save_path)\n",
      "Cell \u001b[0;32mIn [49], line 28\u001b[0m, in \u001b[0;36mtrain_segformer\u001b[0;34m(model, train_dataloader, optimizer, device, epochs, metric)\u001b[0m\n\u001b[1;32m     25\u001b[0m   predicted \u001b[39m=\u001b[39m upsampled_logits\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m   \u001b[39m# note that the metric expects predictions + labels as numpy arrays\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m   metric\u001b[39m.\u001b[39;49madd_batch(predictions\u001b[39m=\u001b[39;49mpredicted\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy(), references\u001b[39m=\u001b[39;49mlabels\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy())\n\u001b[1;32m     30\u001b[0m \u001b[39m# let's print loss and metrics every 100 batches\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/emirenv/lib/python3.10/site-packages/datasets/metric.py:494\u001b[0m, in \u001b[0;36mMetric.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m batch \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpredictions\u001b[39m\u001b[39m\"\u001b[39m: predictions, \u001b[39m\"\u001b[39m\u001b[39mreferences\u001b[39m\u001b[39m\"\u001b[39m: references, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m    493\u001b[0m batch \u001b[39m=\u001b[39m {intput_name: batch[intput_name] \u001b[39mfor\u001b[39;00m intput_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures}\n\u001b[0;32m--> 494\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49mfeatures\u001b[39m.\u001b[39;49mencode_batch(batch)\n\u001b[1;32m    495\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_writer()\n",
      "File \u001b[0;32m~/anaconda3/envs/emirenv/lib/python3.10/site-packages/datasets/features/features.py:1778\u001b[0m, in \u001b[0;36mFeatures.encode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[39mfor\u001b[39;00m key, column \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1777\u001b[0m     column \u001b[39m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 1778\u001b[0m     encoded_batch[key] \u001b[39m=\u001b[39m [encode_nested_example(\u001b[39mself\u001b[39m[key], obj) \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m column]\n\u001b[1;32m   1779\u001b[0m \u001b[39mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/anaconda3/envs/emirenv/lib/python3.10/site-packages/datasets/features/features.py:1778\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[39mfor\u001b[39;00m key, column \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1777\u001b[0m     column \u001b[39m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 1778\u001b[0m     encoded_batch[key] \u001b[39m=\u001b[39m [encode_nested_example(\u001b[39mself\u001b[39;49m[key], obj) \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m column]\n\u001b[1;32m   1779\u001b[0m \u001b[39mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/anaconda3/envs/emirenv/lib/python3.10/site-packages/datasets/features/features.py:1217\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[39m# be careful when comparing tensors here\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m             \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1214\u001b[0m                 \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(first_elmt, \u001b[39mlist\u001b[39m)\n\u001b[1;32m   1215\u001b[0m                 \u001b[39mor\u001b[39;00m encode_nested_example(schema\u001b[39m.\u001b[39mfeature, first_elmt, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m first_elmt\n\u001b[1;32m   1216\u001b[0m             ):\n\u001b[0;32m-> 1217\u001b[0m                 \u001b[39mreturn\u001b[39;00m [encode_nested_example(schema\u001b[39m.\u001b[39mfeature, o, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m obj]\n\u001b[1;32m   1218\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(obj)\n\u001b[1;32m   1219\u001b[0m \u001b[39m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/emirenv/lib/python3.10/site-packages/datasets/features/features.py:1217\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[39m# be careful when comparing tensors here\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m             \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1214\u001b[0m                 \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(first_elmt, \u001b[39mlist\u001b[39m)\n\u001b[1;32m   1215\u001b[0m                 \u001b[39mor\u001b[39;00m encode_nested_example(schema\u001b[39m.\u001b[39mfeature, first_elmt, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m first_elmt\n\u001b[1;32m   1216\u001b[0m             ):\n\u001b[0;32m-> 1217\u001b[0m                 \u001b[39mreturn\u001b[39;00m [encode_nested_example(schema\u001b[39m.\u001b[39;49mfeature, o, level\u001b[39m=\u001b[39;49mlevel \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m obj]\n\u001b[1;32m   1218\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(obj)\n\u001b[1;32m   1219\u001b[0m \u001b[39m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/emirenv/lib/python3.10/site-packages/datasets/features/features.py:1217\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[39m# be careful when comparing tensors here\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m             \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1214\u001b[0m                 \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(first_elmt, \u001b[39mlist\u001b[39m)\n\u001b[1;32m   1215\u001b[0m                 \u001b[39mor\u001b[39;00m encode_nested_example(schema\u001b[39m.\u001b[39mfeature, first_elmt, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m first_elmt\n\u001b[1;32m   1216\u001b[0m             ):\n\u001b[0;32m-> 1217\u001b[0m                 \u001b[39mreturn\u001b[39;00m [encode_nested_example(schema\u001b[39m.\u001b[39mfeature, o, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m obj]\n\u001b[1;32m   1218\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(obj)\n\u001b[1;32m   1219\u001b[0m \u001b[39m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/emirenv/lib/python3.10/site-packages/datasets/features/features.py:1217\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[39m# be careful when comparing tensors here\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m             \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1214\u001b[0m                 \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(first_elmt, \u001b[39mlist\u001b[39m)\n\u001b[1;32m   1215\u001b[0m                 \u001b[39mor\u001b[39;00m encode_nested_example(schema\u001b[39m.\u001b[39mfeature, first_elmt, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m first_elmt\n\u001b[1;32m   1216\u001b[0m             ):\n\u001b[0;32m-> 1217\u001b[0m                 \u001b[39mreturn\u001b[39;00m [encode_nested_example(schema\u001b[39m.\u001b[39;49mfeature, o, level\u001b[39m=\u001b[39;49mlevel \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m obj]\n\u001b[1;32m   1218\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(obj)\n\u001b[1;32m   1219\u001b[0m \u001b[39m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/emirenv/lib/python3.10/site-packages/datasets/features/features.py:1175\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGot None but expected a dictionary instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1166\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m   1167\u001b[0m         {\n\u001b[1;32m   1168\u001b[0m             k: encode_nested_example(sub_schema, sub_obj, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(schema, (\u001b[39mlist\u001b[39;49m, \u001b[39mtuple\u001b[39;49m)):\n\u001b[1;32m   1176\u001b[0m     sub_schema \u001b[39m=\u001b[39m schema[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1177\u001b[0m     \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_segformer(model=model, train_dataloader=train_dataloader, metric=metric, optimizer=optimizer, device=device, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./output/model.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('emirenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12387375b9bdc6a02744d740ba1c0f3a29dccca8b0d19fb734bd586653bcb972"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
